# Generative AI for Computer Vision

This repository provides resources and labs to explore the foundations of Generative AI techniques applied to computer vision. It includes practical implementations and comparisons of state-of-the-art generative models.

## Branches

### `lab1`: VAE and GAN
In this lab, you will implement a Variational Autoencoder (VAE) to reconstruct images and explore its latent space. You will also conceptualize and implement a Generative Adversarial Network (GAN) to understand their differences and reflect on their respective strengths and weaknesses in generative modeling.

### `lab2`: GAN and Attention Mechanism
In this lab, you will explore advanced generative modeling by integrating attention mechanisms into GAN architectures. This lab is divided into two sub-labs:

- ***1.Advanced Generative Adversarial Networks (GANs):***
    1. **Implement a CNN-based GAN** to generate realistic images.
    2. **Integrate Transformer-based architectures** into the GAN framework to leverage the power of attention for generative modeling.
    3. **Compare the performance and visual outputs** of both CNN-based and Transformer-based GANs.
    4. **Reflect on the strengths and challenges** of using CNNs versus Transformers in the context of adversarial training and image generation.

- ***2.Implementing Self-Attention in TensorFlow:***
    1. **Implement a basic self-attention mechanism** using TensorFlow.
    2. **Apply the self-attention module** to a small sequence of words to observe how attention enhances feature representation.
    3. **Analyze the impact** of self-attention on model performance and interpretability in sequence modeling tasks.

